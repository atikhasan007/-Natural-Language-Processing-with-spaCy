{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d93fdb91",
   "metadata": {},
   "source": [
    "Text: The original text of the lexeme.\n",
    "Orth: The hash value of the lexeme.\n",
    "Shape: The abstract word shape of the lexeme.\n",
    "Prefix: By default, the first letter of the word string.\n",
    "Suffix: By default, the last three letters of the word string.\n",
    "is alpha: Does the lexeme consist of alphabetic characters?\n",
    "is digit: Does the lexeme consist of digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dcfe637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.8015960454940796\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "#similarity of two documents\n",
    "print(doc1,\"<->\", doc2, doc1.similarity(doc2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e701b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salty fries\n",
      "hamburgers\n"
     ]
    }
   ],
   "source": [
    "#similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "print(french_fries)\n",
    "burgers = doc1[5]\n",
    "print(burgers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53fd74c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salty fries <-> hamburgers 0.5733411312103271\n"
     ]
    }
   ],
   "source": [
    "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c799d",
   "metadata": {},
   "source": [
    "# Vocab, hashes and lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dcabead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3197928453018144401\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I love coffee\")\n",
    "print(doc.vocab.strings['coffee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a61855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee\n"
     ]
    }
   ],
   "source": [
    "print(doc.vocab.strings[3197928453018144401])  # 'coffee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4d79cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "love\n",
      "coffee\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.text)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5993d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690420944186131903\n",
      "3702023516439754181\n",
      "3197928453018144401\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.orth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f75c7e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "xxxx\n",
      "xxxx\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f5bceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "l\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.prefix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a1040c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "ove\n",
      "fee\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.suffix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b1373fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.is_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "287be24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.is_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15bc48b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.is_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbcbf864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "en\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.lang_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa3f3091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3197928453018144401\n"
     ]
    }
   ],
   "source": [
    "print(doc.vocab.strings['coffee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28f450b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee\n"
     ]
    }
   ],
   "source": [
    "print(doc.vocab.strings[3197928453018144401])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31d9e2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98bd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
