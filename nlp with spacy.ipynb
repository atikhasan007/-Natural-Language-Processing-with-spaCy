{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5960053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I love natural language processing"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I love natural language processing\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511c7c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fcb27d33f2514c4eb68c301f3510db1c-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">love</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">processing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcb27d33f2514c4eb68c301f3510db1c-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcb27d33f2514c4eb68c301f3510db1c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcb27d33f2514c4eb68c301f3510db1c-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcb27d33f2514c4eb68c301f3510db1c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcb27d33f2514c4eb68c301f3510db1c-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcb27d33f2514c4eb68c301f3510db1c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcb27d33f2514c4eb68c301f3510db1c-0-3\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcb27d33f2514c4eb68c301f3510db1c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054ed48",
   "metadata": {},
   "source": [
    "# Name entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8edcce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama PERSON\n",
      "August 4, 1961 DATE\n",
      "Hawaii GPE\n",
      "44th ORDINAL\n",
      "the United States GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Barack Obama was born on August 4, 1961, in Hawaii. He was the 44th President of the United States.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a580ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barack Obama\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was born on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    August 4, 1961\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hawaii\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". He was the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    44th\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " President of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d342c",
   "metadata": {},
   "source": [
    "# Word vectors and sacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0a80d",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc6bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp  = spacy.load(\"en_core_web_md\")\n",
    "# with open (\"data/wiki_us.txt\",'r') as f:\n",
    "#     text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a06c6f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2380b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Barack Obama was born on August 4, 1961, in Hawaii. He was the 44th President of the United States."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fa106a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Barack Obama was born on August 4, 1961, in Hawaii. He was the 44th President of the United States."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df2feaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Barack Obama was born on August 4, 1961, in Hawaii."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1 = list(doc.sents)[0]\n",
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6251b3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'sports': ['GYMNASIUM', 'tennis', 'RINK']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")  # Ensure medium/large model\n",
    "your_word = \"sports\"\n",
    "\n",
    "if nlp.vocab[your_word].has_vector:\n",
    "    word_id = nlp.vocab.strings[your_word]\n",
    "    word_vector = nlp.vocab.vectors[word_id]\n",
    "    ms = nlp.vocab.vectors.most_similar(np.asarray([word_vector]), n=3)\n",
    "    words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "    print(\"Similar words to '{}':\".format(your_word), words)\n",
    "else:\n",
    "    print(\"Word vector for '{}' not found.\".format(your_word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d8910",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9b8192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like saalty fries and hamburgers <-> Fast food tastes very good.  0.7530552128924118\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp('I like saalty fries and hamburgers')\n",
    "doc2 = nlp('Fast food tastes very good. ')\n",
    "\n",
    "print(doc1, \"<->\" , doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72325555",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a304d733",
   "metadata": {},
   "source": [
    "# Attirbute Rulers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "576aa6ec",
   "metadata": {},
   "source": [
    "1.Dependency Parser\n",
    "2.EntityLinker\n",
    "3.EntityRecognizer\n",
    "4.EntityRuler\n",
    "5.Lemmatizer\n",
    "6.Morpholog\n",
    "7.sentenceRecognizer\n",
    "8.Sentencizer\n",
    "9.SpanCategorizer\n",
    "10.Tagger\n",
    "11.TextCategorizer\n",
    "12.Tok2Vec\n",
    "13.Tokenizer\n",
    "14.TrainablePipe\n",
    "15.Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0777a4",
   "metadata": {},
   "source": [
    "# 1. Dependency Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc1f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The → det → fox\n",
      "quick → amod → fox\n",
      "brown → amod → fox\n",
      "fox → nsubj → jumps\n",
      "jumps → ROOT → jumps\n",
      "over → prep → jumps\n",
      "the → det → dog\n",
      "lazy → amod → dog\n",
      "dog → pobj → over\n",
      ". → punct → jumps\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The quick brown fox jumps over the lazy dog.\")\n",
    "for token in doc:\n",
    "    print(token.text, \"→\", token.dep_, \"→\", token.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c770424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0279c26873ca4708aea2e91edec60f33-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">jumps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">dog.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0279c26873ca4708aea2e91edec60f33-0-7\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0279c26873ca4708aea2e91edec60f33-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9ce42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa71b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51430a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2aaa21",
   "metadata": {},
   "source": [
    "# EntityRuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbc3c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone GADGET\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler  # ✅ ঠিক নাম\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# EntityRuler যোগ করো\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
    "\n",
    "# কাস্টম প্যাটার্ন যোগ করো\n",
    "ruler.add_patterns([\n",
    "    {\"label\": \"GADGET\", \"pattern\": \"iphone\"}\n",
    "])\n",
    "\n",
    "# টেস্ট টেক্সট\n",
    "doc = nlp(\"I just bought a new iphone\")\n",
    "\n",
    "# চিহ্নিত Entity প্রিন্ট করো\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0a924",
   "metadata": {},
   "source": [
    "# Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd52a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "just just\n",
      "bought buy\n",
      "a a\n",
      "new new\n",
      "iphone iphone\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00541fe",
   "metadata": {},
   "source": [
    "# Morpholog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b61a378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Case=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "just \n",
      "bought Tense=Past|VerbForm=Fin\n",
      "a Definite=Ind|PronType=Art\n",
      "new Degree=Pos\n",
      "iphone Number=Sing\n"
     ]
    }
   ],
   "source": [
    "#grammatical features for example tense number, person etc\n",
    "for token in doc:\n",
    "    print(token.text, token.morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b22cff",
   "metadata": {},
   "source": [
    "# SentenceRecognizer / SentenceSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6ad3cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n",
      "How are you?\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp('hello world! How are you?')\n",
    "for sent in doc3.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89afa41",
   "metadata": {},
   "source": [
    "# Sentencizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80082d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is sentence one.\n",
      "This is sentence two\n"
     ]
    }
   ],
   "source": [
    "#just punctuation pele sents divied kore\n",
    "\n",
    "npl = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "doc4 = nlp(\"This is sentence one. This is sentence two\")\n",
    "for sent in doc4.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e616d4",
   "metadata": {},
   "source": [
    "# SpanCategorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829511e3",
   "metadata": {},
   "source": [
    "# Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d5baed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1687734250.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    give pos (part of speech) tag\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " give pos (part of speech) tag "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b4f52",
   "metadata": {},
   "source": [
    "# TrainablePipe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5adce939",
   "metadata": {},
   "source": [
    "for Custom NLP model development "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbcd83",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c87a8a40",
   "metadata": {},
   "source": [
    "advanced NER, classification, question answering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51a7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d61dccb",
   "metadata": {},
   "source": [
    "# Matchers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f18b0cd",
   "metadata": {},
   "source": [
    "1.DependencyMatcher\n",
    "2.Matcher #Token attribute (POS, text, lemma, shape, is_alpha, etc.) অনুযায়ী শব্দের ধরণ match করে।\n",
    "3.PhraseMatcher #রো বাক্যাংশ (phrase) বা span match করে।\n",
    "# grammatical pattern খুঁজে বের করার জন্য ব্যবহৃত হয়।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31082181",
   "metadata": {},
   "outputs": [],
   "source": [
    "npl = spacy.blank(\"en\")\n",
    "npl.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546727dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2.analyze_pipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4fa11a",
   "metadata": {},
   "source": [
    "# Rules_based_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d3f55",
   "metadata": {},
   "source": [
    "# EntityRuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec037366",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29f71c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.entityruler.EntityRuler at 0x7b1b112c3cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b330320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc',\n",
       "    'pos_acc',\n",
       "    'tag_micro_p',\n",
       "    'tag_micro_r',\n",
       "    'tag_micro_f'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False},\n",
       "  'sentencizer': {'assigns': ['token.is_sent_start', 'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['sents_f', 'sents_p', 'sents_r'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'entity_ruler': [],\n",
       "  'ner': [],\n",
       "  'sentencizer': []},\n",
       " 'attrs': {'token.ent_iob': {'assigns': ['entity_ruler', 'ner'],\n",
       "   'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser', 'sentencizer'],\n",
       "   'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser', 'sentencizer'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ed2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {'label':'GPE', \"pattern\":\"west Chestertenfieldvile\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d413922",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "090b51a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone GADGET\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baddee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp5 = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp5.add_pipe(\"entity_ruler\", before='ner')\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "805dcc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama PERSON\n",
      "August 4, 1961 DATE\n",
      "Hawaii GPE\n",
      "44th ORDINAL\n",
      "the United States GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff5e9f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp6 = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp6.add_pipe(\"entity_ruler\", before=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9093d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {\"label\":\"GPE\", \"pattern\":\"West Chestertenfieldville\"},\n",
    "    {\"label\":\"FILM\", \"pattern\":\"Mr. Deeds\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08bb4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9f57b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama PERSON\n",
      "August 4, 1961 DATE\n",
      "Hawaii GPE\n",
      "44th ORDINAL\n",
      "the United States GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp6(text)\n",
    "for ent in doc.ents:\n",
    "    print( ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab71dcd",
   "metadata": {},
   "source": [
    "# matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae3c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d94508dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: wmattingly@aol.com\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# ✅ ঠিক করা pattern\n",
    "pattern = [{\"LIKE_EMAIL\": True}]\n",
    "matcher.add(\"EMAIL_ADDRESS\", [pattern])\n",
    "\n",
    "doc = nlp(\"This is an email address: wmattingly@aol.com\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(\"Matched:\", span.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f1b56f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(451313080118390996, 3, 4) atik\n",
      "(451313080118390996, 4, 5) hasan\n",
      "(451313080118390996, 9, 10) shirajgong\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"hi i am atik hasan , my home distict shirajgong\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\":\"PROPN\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern])\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e412b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(451313080118390996, 3, 4) atik\n",
      "(451313080118390996, 3, 5) atik hasan\n",
      "(451313080118390996, 4, 5) hasan\n",
      "(451313080118390996, 9, 10) shirajgong\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"hi i am atik hasan , my home distict shirajgong\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\":\"PROPN\",\"OP\":\"+\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern])\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b451994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(451313080118390996, 3, 5) atik hasan\n",
      "(451313080118390996, 9, 10) shirajgong\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"hi i am atik hasan , my home distict shirajgong\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\":\"PROPN\", \"OP\":\"+\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44182c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(451313080118390996, 3, 5) atik hasan\n",
      "(451313080118390996, 9, 10) shirajgong\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"hi i am atik hasan , my home distict shirajgong\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\":\"PROPN\", \"OP\":\"+\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "550402cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Hi, I am Atik Hasan.\n",
    "I live in a beautiful place.\n",
    "My home district is Shirajganj.\n",
    "It's full of rivers and natural beauty.\n",
    "I love talking about my roots and culture.\"\"\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\":\"PROPN\", \"OP\":\"+\"},{\"POS\":\"VERB\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8811f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Hi, I am.Atik Hasan.\n",
    "I live in a beautiful place.\n",
    "My home district is Shirajganj.\n",
    "It's full of rivers and natural beauty.\n",
    "I love talking about.my roots and culture.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a7422cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I am Atik Hasan \n",
      "I live in a beautiful place \n",
      "My home district is Shirajganj \n",
      "It's full of rivers and natural beauty \n",
      "I love talking about my roots and culture \n"
     ]
    }
   ],
   "source": [
    "text = text.replace(\".\",\" \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "536c4b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(451313080118390996, 54, 62) 'To become great one day.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"Hi, I am Atik Hasan.\n",
    "My friend said, 'Dream big, work hard!'\n",
    "I replied, 'Sure, I believe in that.'\n",
    "Later, someone asked me, 'What's your plan?'\n",
    "I just smiled and said, 'To become great one day.'\"\"\"\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"ORTH\":\"'\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\":\"+\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\":\"*\"},\n",
    "    {\"ORTH\":\"'\"}\n",
    "]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79fb7612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"Hi, I am Atik Hasan.\n",
    "My friend said, 'Dream big, work hard!'\n",
    "I replied, 'Sure, I believe in that.'\n",
    "Later, someone asked me, 'What's your plan?'\n",
    "I just smiled and said, 'To become great one day.'\"\"\"\n",
    "\n",
    "\n",
    "speak_lemmas = [\"think\", \"say\"]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"ORTH\":\"'\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\":\"+\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\":\"*\"},\n",
    "    {\"ORTH\":\"'\"},\n",
    "    {\"POS\":\"VERB\",\"LEMMA\":{\"IN\":speak_lemmas}}\n",
    "]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "861f8642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"Hi, I am Atik Hasan.\n",
    "My friend said, 'Dream big, work hard!'\n",
    "I replied, 'Sure, I believe in that.'\n",
    "Later, someone asked me, 'What's your plan?'\n",
    "I just smiled and said, 'To become great one day.'\"\"\"\n",
    "\n",
    "\n",
    "speak_lemmas = [\"think\", \"say\"]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"ORTH\":\"'\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\":\"+\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\":\"*\"},\n",
    "    {\"ORTH\":\"'\"},\n",
    "    {\"POS\":\"VERB\",\"LEMMA\":{\"IN\":speak_lemmas}},\n",
    "    {\"POS\":\"PROPN\",\"OP\":\"+\"},\n",
    "    {\"ORTH\":\"'\"}\n",
    "]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print(len(matches))\n",
    "\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44f1d7",
   "metadata": {},
   "source": [
    "# Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b4ab69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.language import Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d38156d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Britain is a place. Mary is a doctor.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c75a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Britain GPE\n",
      "Mary PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed0c9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98f70e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"remove_gpe\")\n",
    "def remove_gpe(doc):\n",
    "    original_ents = list(doc.ents)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"GPE\":\n",
    "            original_ents.remove(ent)\n",
    "    doc.ents = original_ents\n",
    "    return (doc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7aa98bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.remove_gpe(doc)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"remove_gpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab232350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc',\n",
       "    'pos_acc',\n",
       "    'tag_micro_p',\n",
       "    'tag_micro_r',\n",
       "    'tag_micro_f'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False},\n",
       "  'remove_gpe': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': [],\n",
       "  'remove_gpe': []},\n",
       " 'attrs': {'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []}}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e88c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary PERSON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Britain is a place. Mary is a doctor.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7f8a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# সব parent ফোল্ডার সহ তৈরি করবে\n",
    "Path(\"data/new_en_core_web_sm\").mkdir(parents=True, exist_ok=True)\n",
    "nlp.to_disk(\"data/new_en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf142b86",
   "metadata": {},
   "source": [
    "# RegEx (basics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2410221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requisite Library\n",
    "import spacy\n",
    "\n",
    "# Sample text\n",
    "text = \"This is a sample number (555) 555-5555.\"\n",
    "\n",
    "# Build a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add the EntityRuler pipeline\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "# Patterns (✅ Correct REGEX structure)\n",
    "patterns = [\n",
    "    {\n",
    "        \"label\": \"PHONE_NUMBER\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": {\"REGEX\": r\"\\(?\\d{3}\\)?[\\s-]?\\d{3}-\\d{4}\"}}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add patterns to the ruler\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the matches\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e109d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4dbe1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Paul Newman was an American actor, but\n",
    "Paul Hollywood is a British TV Host. The name\n",
    "Paul is quit common.\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79a4e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"Paul [A-Z]\\w+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5224f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 11), match='Paul Newman'>\n",
      "<re.Match object; span=(39, 53), match='Paul Hollywood'>\n"
     ]
    }
   ],
   "source": [
    "matches = re.finditer(pattern, text)\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9df40d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dc139f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Walker\n",
      "Paul Newman\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Text\n",
    "text = \"Paul Walker is a great actor. Paul Newman was a racer.\"\n",
    "\n",
    "# Create a blank NLP pipeline\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Save original entities (though spaCy.blank(\"en\") won't have any by default)\n",
    "original_ents = list(doc.ents)\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = r\"Paul [A-Z]\\w+\"\n",
    "\n",
    "# Find matches using regex and convert to spans\n",
    "mwt_ents = []\n",
    "for match in re.finditer(pattern, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    if span:  # span could be None\n",
    "        print(span.text)\n",
    "        mwt_ents.append(span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297ebfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
